{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import typing\n",
    "\n",
    "import rich\n",
    "from rich.progress import track\n",
    "\n",
    "import pandas\n",
    "import transformers\n",
    "import evaluate\n",
    "\n",
    "import cltrier_lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pandas.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "RAW_DATASET: str = \"../data/interim/twitter.german.dataset.enriched.csv\"\n",
    "TEST_SIZE: int = 50\n",
    "\n",
    "MODELS: typing.Dict[str, str] = {\n",
    "    \"base\": \"meta-llama/Llama-3.2-3B-Instruct\", \n",
    "    \"adapter\": \"simon-muenker/Llama-3.2-3B-Instruct-OSN-replies\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8203a74760124cd68794103ab6502c0e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "70073c55321f4189b7573ae34c335892",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:1\n"
     ]
    }
   ],
   "source": [
    "pipelines: typing.Dict[str, transformers.Pipeline] = twon_agents.util.load_pipelines(MODELS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Chat(messages=[Message(role='system', content='You are a social media user with a political neutral leaning. Respond to the following Tweet:'), Message(role='user', content='Nicht der #Verbrenner schadet dem #Klima, sondern der fossile Sprit, mit dem er fährt. Wir haben diese Woche den Weg für klimaneutrale #eFuels freigemacht. Damit könnten die mehr als 45 Mio. Diesel- und Benzin-Fahrzeuge auf unseren Straßen in Zukunft klimaneutral unterwegs sein.'), Message(role='assistant', content='Sie haben wirklich keine Ahnung.')]),\n",
       " Chat(messages=[Message(role='system', content='You are a social media user with a political neutral leaning. Respond to the following Tweet:'), Message(role='user', content='Wo waren die ganzen plötzlichen #Kernkraftbefürworter in #Altparteien, Verbänden &amp; Medien in den letzten Jahren? Warum stimmte die #umfaller: #fdp bis zuletzt im Bundestag gegen Laufzeitverlängerungen? Fakt ist: nur die #AfD lag von Anfang an &amp; jahrelang richtig &amp; blieb auf Kurs!'), Message(role='assistant', content='Nö. Die liegt permanent falsch.')]),\n",
       " Chat(messages=[Message(role='system', content='You are a social media user with a political right leaning. Respond to the following Tweet:'), Message(role='user', content='Die FDP Ostwestfalen-Lippe spricht sich für die Verlängerung der Laufzeiten der Kernkraftwerke aus.'), Message(role='assistant', content='Dann bauen wir doch da ein KKW hin.')])]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset: typing.List[cltrier_lib.inference.schemas.Chat] = [\n",
    "    cltrier_lib.inference.schemas.Chat(messages=[\n",
    "        cltrier_lib.inference.schemas.Message(role=\"system\", content=f\"You are a social media user with a political {row['leaning_reply']} leaning. Respond to the following Tweet:\"),\n",
    "        cltrier_lib.inference.schemas.Message(role=\"user\", content=row[\"text_post\"]),\n",
    "        cltrier_lib.inference.schemas.Message(role=\"assistant\", content=row[\"text_reply\"])\n",
    "    ])\n",
    "    for _, row in pandas.read_csv(RAW_DATASET, index_col=0).iterrows()\n",
    "]\n",
    "dataset[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "17eeb2388d2246d4bc1c820ecea4476c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "responses = []\n",
    "\n",
    "for idx, chat in enumerate(track(dataset[:TEST_SIZE])):\n",
    "    responses.append(\n",
    "        dict(\n",
    "            id=idx,\n",
    "            model=\"human\",\n",
    "            reply=chat[-1].content\n",
    "        )\n",
    "    )\n",
    "\n",
    "    for model, pipeline in pipelines.items():\n",
    "        reply = pipeline(\n",
    "            pipeline.tokenizer.apply_chat_template(chat[:-1], tokenize=False), \n",
    "            max_new_tokens=128,\n",
    "            return_full_text=False\n",
    "        )[0][\"generated_text\"].split(\"\\n\\n\")[1]\n",
    "\n",
    "        responses.append(\n",
    "            dict(\n",
    "                id=idx,\n",
    "                model=model,\n",
    "                reply=reply\n",
    "            )\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_4d643_row0_col0, #T_4d643_row0_col1, #T_4d643_row0_col2, #T_4d643_row1_col0, #T_4d643_row1_col1, #T_4d643_row1_col2, #T_4d643_row2_col0, #T_4d643_row2_col1, #T_4d643_row2_col2, #T_4d643_row3_col0, #T_4d643_row3_col1, #T_4d643_row3_col2, #T_4d643_row4_col0, #T_4d643_row4_col1, #T_4d643_row4_col2 {\n",
       "  text-align: left;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_4d643\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_4d643_level0_col0\" class=\"col_heading level0 col0\" colspan=\"3\">reply</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th class=\"index_name level1\" >model</th>\n",
       "      <th id=\"T_4d643_level1_col0\" class=\"col_heading level1 col0\" >adapter</th>\n",
       "      <th id=\"T_4d643_level1_col1\" class=\"col_heading level1 col1\" >base</th>\n",
       "      <th id=\"T_4d643_level1_col2\" class=\"col_heading level1 col2\" >human</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th class=\"index_name level0\" >id</th>\n",
       "      <th class=\"blank col0\" >&nbsp;</th>\n",
       "      <th class=\"blank col1\" >&nbsp;</th>\n",
       "      <th class=\"blank col2\" >&nbsp;</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_4d643_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_4d643_row0_col0\" class=\"data row0 col0\" >Habe ich richtig gehört? Die Firma #Shell ist eine der ersten, die sich entschied, die #eFuels zu verkaufen. Das ist ein weiterer Grund, warum die #Klimaschutzpolitik so kontraproduktiv ist.</td>\n",
       "      <td id=\"T_4d643_row0_col1\" class=\"data row0 col1\" >Das ist ein interessanter Ansatz! Die Förderung von klimaneutralen #eFuels ist ein wichtiger Schritt in Richtung einer nachhaltigeren Mobilität. Es ist jedoch wichtig, dass wir uns auch auf die Umsetzung und die Auswirkungen dieser Maßnahmen konzentrieren.</td>\n",
       "      <td id=\"T_4d643_row0_col2\" class=\"data row0 col2\" >Sie haben wirklich keine Ahnung.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4d643_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_4d643_row1_col0\" class=\"data row1 col0\" >Naja, ich denke, das war einfach nur, weil die FDP nicht in die Verantwortung trat, die Kernkraft zu schließen.</td>\n",
       "      <td id=\"T_4d643_row1_col1\" class=\"data row1 col1\" >Das ist ein interessantes Thema!</td>\n",
       "      <td id=\"T_4d643_row1_col2\" class=\"data row1 col2\" >Nö. Die liegt permanent falsch.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4d643_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_4d643_row2_col0\" class=\"data row2 col0\" >Aber warum soll man das nicht auch für die @FDP Ostwestfalen-Lippe tun?</td>\n",
       "      <td id=\"T_4d643_row2_col1\" class=\"data row2 col1\" >Das ist ein interessantes Thema! Die FDP ist bekannt für ihre liberale Wirtschaftspolitik und ihre Unterstützung für den Energiezweckverbrauch. Ich denke, es ist wichtig, dass wir uns über die Auswirkungen einer Verlängerung der Laufzeiten der Kernkraftwerke im Einklang mit den Umweltschutzbedenken im Gespräch halten.</td>\n",
       "      <td id=\"T_4d643_row2_col2\" class=\"data row2 col2\" >Dann bauen wir doch da ein KKW hin.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4d643_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_4d643_row3_col0\" class=\"data row3 col0\" >Was wollen Sie denn, Herr #Merkel, mit dieser Frage? Sie wollen uns vor die Wahrheit bringen?</td>\n",
       "      <td id=\"T_4d643_row3_col1\" class=\"data row3 col1\" >\"Auch ich finde das ziemlich besorgniserregend. Es ist wichtig, dass die Regierung transparent über den Besitz von Waffen in unserem Land ist. Die Priorisierung der Inventur von Leoparden gegenüber der Kontrolle von halbautomatischen Gewehren mit Kriegswaffenoptik scheint mir nicht im Einklang mit den Sicherheitsbedenken zu stehen. Ich hoffe, dass die Regierung dies in den nächsten Monat überdacht und eine umfassende Lösung vorschlägt, um die Sicherheit aller B</td>\n",
       "      <td id=\"T_4d643_row3_col2\" class=\"data row3 col2\" > Ok. Stimmt. Sie sind beschämend.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4d643_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_4d643_row4_col0\" class=\"data row4 col0\" >Sie haben ja wirklich keine Ahnung. Die Menschen wollen kein Staat, der alles bezahlt.</td>\n",
       "      <td id=\"T_4d643_row4_col1\" class=\"data row4 col1\" >Ein interessanter Tweet! Es scheint, als ob der Autor sich für eine umfassende Transformation der Energiepolitik und der Mobilitätsstruktur in Deutschland einsetzt. Die Erwähnung von \"Kohle statt Gas\" und \"kernkraftfreundlicher\" deutet auf eine Ablehnung von fossilen Brennstoffen und einer Wende hin. Die Erwähnung von \"eFuels\" und deren Verpöfung zeigt, dass der Autor auch die electric mobility im Blick hat.</td>\n",
       "      <td id=\"T_4d643_row4_col2\" class=\"data row4 col2\" >Ja. Aber Grundsätzlich verstehen Sie mal wieder nichts.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7f3510b50880>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions: pandas.DataFrame = (\n",
    "    pandas.DataFrame(responses)\n",
    "    .set_index(\"id\")\n",
    "    .pivot(columns=[\"model\"])\n",
    ")\n",
    "predictions.head().style.set_properties(**{'text-align': 'left'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">{</span>\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'bleu'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0028246127480123515</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'precisions'</span>: <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.08097636574970941</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.004741209008297116</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.00040306328093510683</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.00041135335252982314</span><span style=\"font-weight: bold\">]</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'brevity_penalty'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.0</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'length_ratio'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2.452471482889734</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'translation_length'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2580</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'reference_length'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1052</span>\n",
       "<span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m{\u001b[0m\n",
       "    \u001b[32m'bleu'\u001b[0m: \u001b[1;36m0.0028246127480123515\u001b[0m,\n",
       "    \u001b[32m'precisions'\u001b[0m: \u001b[1m[\u001b[0m\u001b[1;36m0.08097636574970941\u001b[0m, \u001b[1;36m0.004741209008297116\u001b[0m, \u001b[1;36m0.00040306328093510683\u001b[0m, \u001b[1;36m0.00041135335252982314\u001b[0m\u001b[1m]\u001b[0m,\n",
       "    \u001b[32m'brevity_penalty'\u001b[0m: \u001b[1;36m1.0\u001b[0m,\n",
       "    \u001b[32m'length_ratio'\u001b[0m: \u001b[1;36m2.452471482889734\u001b[0m,\n",
       "    \u001b[32m'translation_length'\u001b[0m: \u001b[1;36m2580\u001b[0m,\n",
       "    \u001b[32m'reference_length'\u001b[0m: \u001b[1;36m1052\u001b[0m\n",
       "\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "scores_base = evaluate.load(\"bleu\").compute(\n",
    "    references=predictions[(\"reply\", \"human\")].tolist(),\n",
    "    predictions=predictions[(\"reply\", \"base\")].tolist(),\n",
    "    smooth=True\n",
    ")\n",
    "rich.print(scores_base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">{</span>\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'bleu'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.016412250786555563</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'precisions'</span>: <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.11329170383586083</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.015873015873015872</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.007835455435847209</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.005149330587023687</span><span style=\"font-weight: bold\">]</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'brevity_penalty'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.0</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'length_ratio'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.064638783269962</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'translation_length'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1120</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'reference_length'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1052</span>\n",
       "<span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m{\u001b[0m\n",
       "    \u001b[32m'bleu'\u001b[0m: \u001b[1;36m0.016412250786555563\u001b[0m,\n",
       "    \u001b[32m'precisions'\u001b[0m: \u001b[1m[\u001b[0m\u001b[1;36m0.11329170383586083\u001b[0m, \u001b[1;36m0.015873015873015872\u001b[0m, \u001b[1;36m0.007835455435847209\u001b[0m, \u001b[1;36m0.005149330587023687\u001b[0m\u001b[1m]\u001b[0m,\n",
       "    \u001b[32m'brevity_penalty'\u001b[0m: \u001b[1;36m1.0\u001b[0m,\n",
       "    \u001b[32m'length_ratio'\u001b[0m: \u001b[1;36m1.064638783269962\u001b[0m,\n",
       "    \u001b[32m'translation_length'\u001b[0m: \u001b[1;36m1120\u001b[0m,\n",
       "    \u001b[32m'reference_length'\u001b[0m: \u001b[1;36m1052\u001b[0m\n",
       "\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "scores_adapter = evaluate.load(\"bleu\").compute(\n",
    "    references=predictions[(\"reply\", \"human\")].tolist(),\n",
    "    predictions=predictions[(\"reply\", \"adapter\")].tolist(),\n",
    "    smooth=True\n",
    ")\n",
    "rich.print(scores_adapter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lll}\n",
      "\\toprule\n",
      " & prompt & fine-tuned \\\\\n",
      "\\midrule\n",
      "bleu & 0.002825 & 0.016412 \\\\\n",
      "precisions & [0.08097636574970941, 0.004741209008297116, 0.00040306328093510683, 0.00041135335252982314] & [0.11329170383586083, 0.015873015873015872, 0.007835455435847209, 0.005149330587023687] \\\\\n",
      "brevity_penalty & 1.000000 & 1.000000 \\\\\n",
      "length_ratio & 2.452471 & 1.064639 \\\\\n",
      "translation_length & 2580 & 1120 \\\\\n",
      "reference_length & 1052 & 1052 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    pandas.DataFrame({\n",
    "        \"prompt\": scores_base,\n",
    "        \"fine-tuned\": scores_adapter\n",
    "    }).to_latex()\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
