{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import typing\n",
    "\n",
    "import pandas\n",
    "import transformers\n",
    "\n",
    "import cltrier_lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODELS: typing.Dict[str, str] = {\n",
    "    \"base\": \"meta-llama/Llama-3.2-3B-Instruct\", \n",
    "    \"adapter\": \"simon-muenker/Llama-3.2-3B-Instruct-OSN-replies\"\n",
    "}\n",
    "LEANINGS: typing.List[str] = [\"left\", \"neutral\", \"right\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "INSTRUCTION = cltrier_lib.inference.schemas.Message(role=\"system\", content=\"You are a social media user with a political {leaning} leaning. Respond to the following Tweet:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAMPLES: typing.List[str] = [\n",
    "    \"Die FDP Ostwestfalen-Lippe spricht sich für die Verlängerung der Laufzeiten der Kernkraftwerke aus.\",\n",
    "    \"Seit 10 Tagen sind wir aus der #Atomkraft ausgestiegen. Das Licht brennt trotzdem zuverlässig und unser Land ist sicherer und freier geworden.\",\n",
    "    \"Berlin ohne Autos - das könnte so schön sein!  So viel Platz, so viel Ruhe, so gute Luft.\",\n",
    "    \"Wer pauschal über 'Sozialtourismus' und 'kleine Paschas' spricht, der kann keinen Führungsanspruch für das moderne Deutschland begründen!\",\n",
    "    \"Wie lange wird die Diskussion ums #Tempolimit wohl noch gehen bis das Tempolimit endlich kommt?\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "pipelines: typing.Dict[str, transformers.Pipeline] = {\n",
    "    label: transformers.pipeline(\"text-generation\", slug, device=f\"cuda:{n}\")\n",
    "    for n, (label, slug) in enumerate(MODELS.items())\n",
    "}\n",
    "\n",
    "pipelines[\"adapter\"].model.load_adapter(MODELS[\"adapter\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "responses = []\n",
    "\n",
    "for idx, post in enumerate(SAMPLES):\n",
    "    for leaning in LEANINGS:\n",
    "        for model, pipeline in pipelines.items():\n",
    "            chat = cltrier_lib.inference.schemas.Chat(messages=[\n",
    "                INSTRUCTION.format_content(leaning=leaning),\n",
    "                cltrier_lib.inference.schemas.Message(role=\"user\", content=post)\n",
    "            ])\n",
    "\n",
    "            reply = pipeline(\n",
    "                pipeline.tokenizer.apply_chat_template(chat, tokenize=False), \n",
    "                max_new_tokens=128,\n",
    "                return_full_text=False\n",
    "            )[0][\"generated_text\"].split(\"\\n\\n\")[1]\n",
    "\n",
    "            responses.append(\n",
    "                dict(\n",
    "                    id=idx,\n",
    "                    leaning=leaning, \n",
    "                    model=model, \n",
    "                    post=post,\n",
    "                    reply=reply\n",
    "                )\n",
    "            )\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pandas.set_option('display.max_colwidth', None)\n",
    "\n",
    "(\n",
    "    pandas.DataFrame(responses)\n",
    "    .set_index([\"id\", \"leaning\", \"model\"])\n",
    "    .style.set_properties(**{'text-align': 'left'})\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
