{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import typing\n",
    "\n",
    "import rich\n",
    "from rich.progress import track\n",
    "\n",
    "import pandas\n",
    "import transformers\n",
    "import evaluate\n",
    "\n",
    "import cltrier_lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pandas.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "RAW_DATASET: str = \"../data/interim/twitter.german.dataset.enriched.csv\"\n",
    "TEST_SIZE: int = 50\n",
    "\n",
    "MODELS: typing.Dict[str, str] = {\n",
    "    \"base\": \"meta-llama/Llama-3.2-3B-Instruct\", \n",
    "    \"adapter\": \"simon-muenker/Llama-3.2-3B-Instruct-OSN-posts\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "65f195c6a489441d9da10d4508c3c9d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78ebcb8fb78b4bf2ab56fac9415b3467",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:1\n"
     ]
    }
   ],
   "source": [
    "pipelines: typing.Dict[str, transformers.Pipeline] = {\n",
    "    label: transformers.pipeline(\"text-generation\", slug, device=f\"cuda:{1}\")\n",
    "    for n, (label, slug) in enumerate(MODELS.items())\n",
    "}\n",
    "\n",
    "pipelines[\"adapter\"].model.load_adapter(MODELS[\"adapter\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Chat(messages=[Message(role='system', content='You are a social media user with a political neutral leaning. Post a Tweet about the following topic:'), Message(role='user', content='Klima, eFuels, Verbrenner'), Message(role='assistant', content='Nicht der #Verbrenner schadet dem #Klima, sondern der fossile Sprit, mit dem er fährt. Wir haben diese Woche den Weg für klimaneutrale #eFuels freigemacht. Damit könnten die mehr als 45 Mio. Diesel- und Benzin-Fahrzeuge auf unseren Straßen in Zukunft klimaneutral unterwegs sein.')]),\n",
       " Chat(messages=[Message(role='system', content='You are a social media user with a political right leaning. Post a Tweet about the following topic:'), Message(role='user', content='Kernkraft, Altparteien, AfD'), Message(role='assistant', content='Wo waren die ganzen plötzlichen #Kernkraftbefürworter in #Altparteien, Verbänden &amp; Medien in den letzten Jahren? Warum stimmte die #umfaller: #fdp bis zuletzt im Bundestag gegen Laufzeitverlängerungen? Fakt ist: nur die #AfD lag von Anfang an &amp; jahrelang richtig &amp; blieb auf Kurs!')]),\n",
       " Chat(messages=[Message(role='system', content='You are a social media user with a political right leaning. Post a Tweet about the following topic:'), Message(role='user', content='FDP, Kernkraftwerke, Ostwestfalen-Lippe'), Message(role='assistant', content='Die FDP Ostwestfalen-Lippe spricht sich für die Verlängerung der Laufzeiten der Kernkraftwerke aus.')])]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset: typing.List[cltrier_lib.inference.schemas.Chat] = [\n",
    "    cltrier_lib.inference.schemas.Chat(messages=[\n",
    "        cltrier_lib.inference.schemas.Message(role=\"system\", content=f\"You are a social media user with a political {row['leaning_post']} leaning. Post a Tweet about the following topic:\"),\n",
    "        cltrier_lib.inference.schemas.Message(role=\"user\", content=row[\"topics_post\"]),\n",
    "        cltrier_lib.inference.schemas.Message(role=\"assistant\", content=row[\"text_post\"])\n",
    "    ])\n",
    "    for _, row in pandas.read_csv(RAW_DATASET, index_col=0).iterrows()\n",
    "]\n",
    "dataset[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "489a13cd31d042b4870df2b7dc6254a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "responses = []\n",
    "\n",
    "for idx, chat in enumerate(track(dataset[:TEST_SIZE])):\n",
    "    responses.append(\n",
    "        dict(\n",
    "            id=idx,\n",
    "            model=\"human\",\n",
    "            reply=chat[-1].content\n",
    "        )\n",
    "    )\n",
    "\n",
    "    for model, pipeline in pipelines.items():\n",
    "        reply = pipeline(\n",
    "            pipeline.tokenizer.apply_chat_template(chat[:-1], tokenize=False), \n",
    "            max_new_tokens=128,\n",
    "            return_full_text=False\n",
    "        )[0][\"generated_text\"].split(\"\\n\\n\")[1]\n",
    "\n",
    "        responses.append(\n",
    "            dict(\n",
    "                id=idx,\n",
    "                model=model,\n",
    "                reply=reply\n",
    "            )\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_d7e09_row0_col0, #T_d7e09_row0_col1, #T_d7e09_row0_col2, #T_d7e09_row1_col0, #T_d7e09_row1_col1, #T_d7e09_row1_col2, #T_d7e09_row2_col0, #T_d7e09_row2_col1, #T_d7e09_row2_col2, #T_d7e09_row3_col0, #T_d7e09_row3_col1, #T_d7e09_row3_col2, #T_d7e09_row4_col0, #T_d7e09_row4_col1, #T_d7e09_row4_col2 {\n",
       "  text-align: left;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_d7e09\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_d7e09_level0_col0\" class=\"col_heading level0 col0\" colspan=\"3\">reply</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th class=\"index_name level1\" >model</th>\n",
       "      <th id=\"T_d7e09_level1_col0\" class=\"col_heading level1 col0\" >adapter</th>\n",
       "      <th id=\"T_d7e09_level1_col1\" class=\"col_heading level1 col1\" >base</th>\n",
       "      <th id=\"T_d7e09_level1_col2\" class=\"col_heading level1 col2\" >human</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th class=\"index_name level0\" >id</th>\n",
       "      <th class=\"blank col0\" >&nbsp;</th>\n",
       "      <th class=\"blank col1\" >&nbsp;</th>\n",
       "      <th class=\"blank col2\" >&nbsp;</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_d7e09_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_d7e09_row0_col0\" class=\"data row0 col0\" >Wir brauchen eine klare Richtlinie für den Umgang mit #eFuels. Das ist nicht nur für die Umwelt, sondern auch für die Menschen in #Koalitionskrise. Dass Verbrenner immer noch gefördert werden, obwohl das Klimaschutzprogramm verabschiedet wurde, ist ein Fehler. #Klimakrise</td>\n",
       "      <td id=\"T_d7e09_row0_col1\" class=\"data row0 col1\" >\"Die Zukunft der Energie ist ein Thema, das uns alle betrifft. Während #Klimaschutz und #ErneuerbareEnergie wichtige Schritte sind, sollten wir auch die Rolle von #eFuels in der Reduzierung von Treibhausgasen nicht außer Acht lassen. Wie denken Sie, können wir eine nachhaltige Zukunft für alle schaffen? #Energie der Zukunft\"</td>\n",
       "      <td id=\"T_d7e09_row0_col2\" class=\"data row0 col2\" >Nicht der #Verbrenner schadet dem #Klima, sondern der fossile Sprit, mit dem er fährt. Wir haben diese Woche den Weg für klimaneutrale #eFuels freigemacht. Damit könnten die mehr als 45 Mio. Diesel- und Benzin-Fahrzeuge auf unseren Straßen in Zukunft klimaneutral unterwegs sein.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d7e09_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_d7e09_row1_col0\" class=\"data row1 col0\" >Dass die Altparteien im Parlament die Abschaffung der Kernkraft für den Energiebedarf für Deutschland vorstehen, ist ein Skandal. Die AfD hingegen war und ist eine Stimme für die Fortsetzung der Kernkraft. Die in Deutschland leuchtend saubere Energie wird auch in Zukunft weiter genutzt.</td>\n",
       "      <td id=\"T_d7e09_row1_col1\" class=\"data row1 col1\" >\"Die #AfD hat sich endlich zu einer echten Oppositionspartei entwickelt! Ihre Forderungen nach fairen Wettbewerb und Regulierungen bei den Energiekraftwerken sind lang überfällig. Es ist Zeit, dass die Politiker endlich auf die Bürger hören und die Marktwirtschaft unterstützen! #Freiheit #Marktwirtschaft\"</td>\n",
       "      <td id=\"T_d7e09_row1_col2\" class=\"data row1 col2\" >Wo waren die ganzen plötzlichen #Kernkraftbefürworter in #Altparteien, Verbänden &amp; Medien in den letzten Jahren? Warum stimmte die #umfaller: #fdp bis zuletzt im Bundestag gegen Laufzeitverlängerungen? Fakt ist: nur die #AfD lag von Anfang an &amp; jahrelang richtig &amp; blieb auf Kurs!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d7e09_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_d7e09_row2_col0\" class=\"data row2 col0\" >Die FDP ist eine gute Partei. Aber man muss auch die kleinen Dinge beachten, wie zum Beispiel das Slogan: „Wir machen den Staat stark, damit er die #Kernkraftwerke schützen kann.“ Das ist ein Rechtsruck. Und das ist nicht nur für die Bürger von #Ostwestfalen-Lippe zu schade.</td>\n",
       "      <td id=\"T_d7e09_row2_col1\" class=\"data row2 col1\" >\"Germany's Energiewende is a costly failure! The FDP and Kernkraftwerke's push for renewable energy is crippling our economy. We need a balanced approach that incorporates reliable, domestic nuclear power like Ostwestfalen-Lippe's innovative solutions. #Energiepolitik #FDP #NuklearEnergie\"</td>\n",
       "      <td id=\"T_d7e09_row2_col2\" class=\"data row2 col2\" >Die FDP Ostwestfalen-Lippe spricht sich für die Verlängerung der Laufzeiten der Kernkraftwerke aus.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d7e09_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_d7e09_row3_col0\" class=\"data row3 col0\" >Wir brauchen eine waffensichere #Leopard-Flotte, aber auch mehr Transparenz in der Regierung! Das ist ein wichtiger Punkt in der Diskussion.  Wir werden das auch mit @BundesministerStoltenberg &amp; #Bundesverteidigung in der Woche besprechen.</td>\n",
       "      <td id=\"T_d7e09_row3_col1\" class=\"data row3 col1\" >\"Die deutsche Regierung muss endlich transparent werden! Die zunehmende Zahl von Waffenbesitzern und der Bestand der Leopard-Tanks muss öffentlich zugänglich gemacht werden. Wir brauchen mehr Sicherheit, aber auch mehr Vertrauen in unser demokratisches System. #Waffenkontrolle #Regierungstransparenz #Deutschland\"</td>\n",
       "      <td id=\"T_d7e09_row3_col2\" class=\"data row3 col2\" >Aus meinem Wahlkreis heute eine Bürgerfrage: \"Bloß mal als Frage, warum weiß die Regierung, daß genau 135.000 halbautomatische Gewehre mit Kriegswaffenoptik im Privatbesitz sind, jedoch muß die beim eigenen Bestand von Leoparden erst mal Inventur machen. Das ist doch beschämend.\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d7e09_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_d7e09_row4_col0\" class=\"data row4 col0\" >Der Klimaschutz muss von der #Kollektiven Mobilität und der #Energiewende abhängen. Wir brauchen eine Klimaschutzpolitik, die die Verkehrsentwicklung als Wettbewerber ausschließt und stattdessen die Verkehrsfähigkeit erhöht. #Fahrrad #Bus</td>\n",
       "      <td id=\"T_d7e09_row4_col1\" class=\"data row4 col1\" >\"Die #Energiewende ist ein wichtiger Schritt in die richtige Richtung, aber wir müssen nicht auf die Billigung von Teilen der #KollektivenMobilität warten! Es ist Zeit, dass wir eine umfassende Lösung für unsere Mobilitätsprobleme entwickeln, die auch die Interessen von Autofahrern und Fußgängern berücksichtigt. #Fahrfreundlichkeit #Verkehrsplanung\"</td>\n",
       "      <td id=\"T_d7e09_row4_col2\" class=\"data row4 col2\" >Kohle statt Gas, Kernkraft als Gegner, eFuels verpönt. Dafür Tempolimit, Verbots- und Enteignungsphantasien, Planwirtschaft mit kollektiver Mobilität und ein Staat, der alles bezahlt.  Es geht schon lange nicht mehr nur um Klimaschutz. Es geht um Grundsätzliches. #kulturwandel</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7f410b7a3f40>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions: pandas.DataFrame = (\n",
    "    pandas.DataFrame(responses)\n",
    "    .set_index(\"id\")\n",
    "    .pivot(columns=[\"model\"])\n",
    ")\n",
    "predictions.head().style.set_properties(**{'text-align': 'left'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">{</span>\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'bleu'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.004295533011426501</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'precisions'</span>: <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.15254237288135594</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.012355848434925865</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.00042052144659377626</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.000429553264604811</span><span style=\"font-weight: bold\">]</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'brevity_penalty'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.0</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'length_ratio'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.2484879032258065</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'translation_length'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2477</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'reference_length'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1984</span>\n",
       "<span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m{\u001b[0m\n",
       "    \u001b[32m'bleu'\u001b[0m: \u001b[1;36m0.004295533011426501\u001b[0m,\n",
       "    \u001b[32m'precisions'\u001b[0m: \u001b[1m[\u001b[0m\u001b[1;36m0.15254237288135594\u001b[0m, \u001b[1;36m0.012355848434925865\u001b[0m, \u001b[1;36m0.00042052144659377626\u001b[0m, \u001b[1;36m0.000429553264604811\u001b[0m\u001b[1m]\u001b[0m,\n",
       "    \u001b[32m'brevity_penalty'\u001b[0m: \u001b[1;36m1.0\u001b[0m,\n",
       "    \u001b[32m'length_ratio'\u001b[0m: \u001b[1;36m1.2484879032258065\u001b[0m,\n",
       "    \u001b[32m'translation_length'\u001b[0m: \u001b[1;36m2477\u001b[0m,\n",
       "    \u001b[32m'reference_length'\u001b[0m: \u001b[1;36m1984\u001b[0m\n",
       "\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "scores_base = evaluate.load(\"bleu\").compute(\n",
    "    references=predictions[(\"reply\", \"human\")].tolist(),\n",
    "    predictions=predictions[(\"reply\", \"base\")].tolist(),\n",
    "    smooth=True\n",
    ")\n",
    "rich.print(scores_base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">{</span>\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'bleu'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.01946525268913204</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'precisions'</span>: <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.22553973357831877</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.035731076633756464</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.007221954742416947</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.00246669955599408</span><span style=\"font-weight: bold\">]</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'brevity_penalty'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.0</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'length_ratio'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.096774193548387</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'translation_length'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2176</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'reference_length'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1984</span>\n",
       "<span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m{\u001b[0m\n",
       "    \u001b[32m'bleu'\u001b[0m: \u001b[1;36m0.01946525268913204\u001b[0m,\n",
       "    \u001b[32m'precisions'\u001b[0m: \u001b[1m[\u001b[0m\u001b[1;36m0.22553973357831877\u001b[0m, \u001b[1;36m0.035731076633756464\u001b[0m, \u001b[1;36m0.007221954742416947\u001b[0m, \u001b[1;36m0.00246669955599408\u001b[0m\u001b[1m]\u001b[0m,\n",
       "    \u001b[32m'brevity_penalty'\u001b[0m: \u001b[1;36m1.0\u001b[0m,\n",
       "    \u001b[32m'length_ratio'\u001b[0m: \u001b[1;36m1.096774193548387\u001b[0m,\n",
       "    \u001b[32m'translation_length'\u001b[0m: \u001b[1;36m2176\u001b[0m,\n",
       "    \u001b[32m'reference_length'\u001b[0m: \u001b[1;36m1984\u001b[0m\n",
       "\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "scores_adapter = evaluate.load(\"bleu\").compute(\n",
    "    references=predictions[(\"reply\", \"human\")].tolist(),\n",
    "    predictions=predictions[(\"reply\", \"adapter\")].tolist(),\n",
    "    smooth=True\n",
    ")\n",
    "rich.print(scores_adapter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lll}\n",
      "\\toprule\n",
      " & prompt & fine-tuned \\\\\n",
      "\\midrule\n",
      "bleu & 0.004296 & 0.019465 \\\\\n",
      "precisions & [0.15254237288135594, 0.012355848434925865, 0.00042052144659377626, 0.000429553264604811] & [0.22553973357831877, 0.035731076633756464, 0.007221954742416947, 0.00246669955599408] \\\\\n",
      "brevity_penalty & 1.000000 & 1.000000 \\\\\n",
      "length_ratio & 1.248488 & 1.096774 \\\\\n",
      "translation_length & 2477 & 2176 \\\\\n",
      "reference_length & 1984 & 1984 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    pandas.DataFrame({\n",
    "        \"prompt\": scores_base,\n",
    "        \"fine-tuned\": scores_adapter\n",
    "    }).to_latex()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'tools' from '/home/ubuntu/apis/TWON-Agents/notebooks/../src/tools/__init__.py'>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "from importlib import reload\n",
    "\n",
    "sys.path.append('../src')\n",
    "\n",
    "import tools\n",
    "reload(tools)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>correlation</th>\n",
       "      <th>correlation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>results.topics.arts_&amp;_culture</th>\n",
       "      <td>0.316324</td>\n",
       "      <td>0.527827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>results.topics.business_&amp;_entrepreneurs</th>\n",
       "      <td>0.823855</td>\n",
       "      <td>0.970664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>results.topics.celebrity_&amp;_pop_culture</th>\n",
       "      <td>-0.064969</td>\n",
       "      <td>0.183695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>results.topics.diaries_&amp;_daily_life</th>\n",
       "      <td>0.268324</td>\n",
       "      <td>0.455055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>results.topics.family</th>\n",
       "      <td>0.418441</td>\n",
       "      <td>0.606716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>results.topics.fashion_&amp;_style</th>\n",
       "      <td>0.061949</td>\n",
       "      <td>0.604102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>results.topics.film_tv_&amp;_video</th>\n",
       "      <td>0.606203</td>\n",
       "      <td>0.367231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>results.topics.fitness_&amp;_health</th>\n",
       "      <td>0.822659</td>\n",
       "      <td>0.690324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>results.topics.food_&amp;_dining</th>\n",
       "      <td>0.441140</td>\n",
       "      <td>0.710177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>results.topics.gaming</th>\n",
       "      <td>0.194686</td>\n",
       "      <td>0.033245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>results.topics.learning_&amp;_educational</th>\n",
       "      <td>0.259473</td>\n",
       "      <td>-0.064828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>results.topics.music</th>\n",
       "      <td>-0.144515</td>\n",
       "      <td>-0.038703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>results.topics.news_&amp;_social_concern</th>\n",
       "      <td>0.310537</td>\n",
       "      <td>0.493245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>results.topics.other_hobbies</th>\n",
       "      <td>0.253877</td>\n",
       "      <td>0.500595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>results.topics.relationships</th>\n",
       "      <td>0.077495</td>\n",
       "      <td>0.366709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>results.topics.science_&amp;_technology</th>\n",
       "      <td>-0.023066</td>\n",
       "      <td>0.641005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>results.topics.sports</th>\n",
       "      <td>0.251146</td>\n",
       "      <td>-0.062891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>results.topics.travel_&amp;_adventure</th>\n",
       "      <td>0.733545</td>\n",
       "      <td>0.803375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>results.topics.youth_&amp;_student_life</th>\n",
       "      <td>0.252673</td>\n",
       "      <td>0.132103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>results.emotions.anger</th>\n",
       "      <td>0.083617</td>\n",
       "      <td>0.420067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>results.emotions.anticipation</th>\n",
       "      <td>-0.065524</td>\n",
       "      <td>0.319859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>results.emotions.disgust</th>\n",
       "      <td>0.100008</td>\n",
       "      <td>0.552181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>results.emotions.fear</th>\n",
       "      <td>0.013846</td>\n",
       "      <td>0.341767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>results.emotions.joy</th>\n",
       "      <td>0.566229</td>\n",
       "      <td>0.446037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>results.emotions.love</th>\n",
       "      <td>0.563486</td>\n",
       "      <td>0.428044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>results.emotions.optimism</th>\n",
       "      <td>0.094971</td>\n",
       "      <td>0.349697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>results.emotions.pessimism</th>\n",
       "      <td>0.064082</td>\n",
       "      <td>0.578193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>results.emotions.sadness</th>\n",
       "      <td>0.094178</td>\n",
       "      <td>0.655140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>results.emotions.surprise</th>\n",
       "      <td>-0.008806</td>\n",
       "      <td>0.015001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>results.emotions.trust</th>\n",
       "      <td>-0.020713</td>\n",
       "      <td>0.279467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>results.sentiment.negative</th>\n",
       "      <td>-0.038422</td>\n",
       "      <td>0.275031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>results.sentiment.neutral</th>\n",
       "      <td>-0.089193</td>\n",
       "      <td>-0.000748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>results.sentiment.positive</th>\n",
       "      <td>0.211031</td>\n",
       "      <td>0.073498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>results.irony.non_irony</th>\n",
       "      <td>-0.084088</td>\n",
       "      <td>-0.028657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>results.irony.irony</th>\n",
       "      <td>-0.113088</td>\n",
       "      <td>-0.033477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>results.offensive.non-offensive</th>\n",
       "      <td>0.279708</td>\n",
       "      <td>0.220909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>results.offensive.offensive</th>\n",
       "      <td>0.357153</td>\n",
       "      <td>0.089451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>results.hate.NOT-HATE</th>\n",
       "      <td>0.003340</td>\n",
       "      <td>0.289325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>results.hate.HATE</th>\n",
       "      <td>-0.025433</td>\n",
       "      <td>0.350122</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         correlation  correlation\n",
       "results.topics.arts_&_culture               0.316324     0.527827\n",
       "results.topics.business_&_entrepreneurs     0.823855     0.970664\n",
       "results.topics.celebrity_&_pop_culture     -0.064969     0.183695\n",
       "results.topics.diaries_&_daily_life         0.268324     0.455055\n",
       "results.topics.family                       0.418441     0.606716\n",
       "results.topics.fashion_&_style              0.061949     0.604102\n",
       "results.topics.film_tv_&_video              0.606203     0.367231\n",
       "results.topics.fitness_&_health             0.822659     0.690324\n",
       "results.topics.food_&_dining                0.441140     0.710177\n",
       "results.topics.gaming                       0.194686     0.033245\n",
       "results.topics.learning_&_educational       0.259473    -0.064828\n",
       "results.topics.music                       -0.144515    -0.038703\n",
       "results.topics.news_&_social_concern        0.310537     0.493245\n",
       "results.topics.other_hobbies                0.253877     0.500595\n",
       "results.topics.relationships                0.077495     0.366709\n",
       "results.topics.science_&_technology        -0.023066     0.641005\n",
       "results.topics.sports                       0.251146    -0.062891\n",
       "results.topics.travel_&_adventure           0.733545     0.803375\n",
       "results.topics.youth_&_student_life         0.252673     0.132103\n",
       "results.emotions.anger                      0.083617     0.420067\n",
       "results.emotions.anticipation              -0.065524     0.319859\n",
       "results.emotions.disgust                    0.100008     0.552181\n",
       "results.emotions.fear                       0.013846     0.341767\n",
       "results.emotions.joy                        0.566229     0.446037\n",
       "results.emotions.love                       0.563486     0.428044\n",
       "results.emotions.optimism                   0.094971     0.349697\n",
       "results.emotions.pessimism                  0.064082     0.578193\n",
       "results.emotions.sadness                    0.094178     0.655140\n",
       "results.emotions.surprise                  -0.008806     0.015001\n",
       "results.emotions.trust                     -0.020713     0.279467\n",
       "results.sentiment.negative                 -0.038422     0.275031\n",
       "results.sentiment.neutral                  -0.089193    -0.000748\n",
       "results.sentiment.positive                  0.211031     0.073498\n",
       "results.irony.non_irony                    -0.084088    -0.028657\n",
       "results.irony.irony                        -0.113088    -0.033477\n",
       "results.offensive.non-offensive             0.279708     0.220909\n",
       "results.offensive.offensive                 0.357153     0.089451\n",
       "results.hate.NOT-HATE                       0.003340     0.289325\n",
       "results.hate.HATE                          -0.025433     0.350122"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classify_corr = pandas.concat([\n",
    "    tools.Evaluate()(\n",
    "        source=predictions[(\"reply\", \"human\")].tolist(),\n",
    "        target=predictions[(\"reply\", \"base\")].tolist()\n",
    "    )[0],\n",
    "    tools.Evaluate()(\n",
    "        source=predictions[(\"reply\", \"human\")].tolist(),\n",
    "        target=predictions[(\"reply\", \"adapter\")].tolist()\n",
    "    )[0]\n",
    "], axis=1, names=[\"base\", \"adapter\"])\n",
    "classify_corr"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
