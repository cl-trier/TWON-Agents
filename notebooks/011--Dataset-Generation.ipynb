{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import typing\n",
    "import pathlib\n",
    "\n",
    "import rich.progress\n",
    "import pandas\n",
    "import cltrier_lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXPORT_PATH: str = \"../data/interim/twitter.german.dataset.enriched.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset: pandas.DataFrame = (\n",
    "    pandas.merge(\n",
    "        pandas.read_csv(\"../data/interim/twitter.german.replies.csv\", index_col=0),\n",
    "        pandas.read_csv(\"../data/interim/twitter.german.posts.csv\", index_col=0),\n",
    "        how=\"left\",\n",
    "        left_on=\"conversation_id\",\n",
    "        right_on=\"id\",\n",
    "        suffixes=(\"_reply\", \"_post\")\n",
    "    )\n",
    "    .rename(columns=dict(username=\"author_post\", first_name=\"author_first_name_post\", last_name=\"author_last_name_post\", party=\"author_party_post\"))\n",
    "    [[\"id_post\", \"id_reply\", \"author_id_post\", \"author_id_reply\", \"author_first_name_post\", \"author_last_name_post\", \"author_party_post\", \"text_post\", \"text_reply\"]]\n",
    ")\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.to_csv(EXPORT_PATH.replace(\".enriched\", \"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_extraction_instruction: str = \"\"\"Your task is to extract the main topics of the given tweet. Summarize topics exceeding 10 characters. Keep the total number of topics to 3 or fewer. \n",
    "\n",
    "Respond only with the topic names separated by commas. Omit any justification. This is the tweet: \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for new_col, source_col, instruction in [\n",
    "    (\"topics_post\", \"text_post\", topic_extraction_instruction),\n",
    "    (\"topics_reply\", \"text_reply\", topic_extraction_instruction),\n",
    "]:  \n",
    "    \n",
    "    if pathlib.Path(EXPORT_PATH).is_file():\n",
    "        dataset = pandas.read_csv(EXPORT_PATH, index_col=0)\n",
    "\n",
    "    if new_col not in dataset.columns:\n",
    "        \n",
    "        predictions: typing.List[str] = [\n",
    "            cltrier_lib.inference.Pipeline()(\n",
    "                chat= cltrier_lib.inference.schemas.Chat(messages=[\n",
    "                    cltrier_lib.inference.schemas.Message(role=\"system\", content=instruction),\n",
    "                    cltrier_lib.inference.schemas.Message(role=\"user\", content=content)\n",
    "                ])\n",
    "            )[-1].content\n",
    "            for content in rich.progress.track(dataset[source_col])\n",
    "        ]\n",
    "\n",
    "        dataset = dataset.assign(**{new_col: predictions})\n",
    "        dataset.to_csv(EXPORT_PATH)\n",
    "    \n",
    "    display(dataset[new_col].value_counts())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# manual (human) filtering and reduction of topics, comparison and unification with topics_reply to improve the dataset quality\n",
    "list(dataset[\"topics_post\"].str.split(\",\").explode().str.strip().drop_duplicates())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
